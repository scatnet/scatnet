\documentclass[twocolumn]{article}
\usepackage{amsmath,cite}
\usepackage{graphicx}

\usepackage{amssymb}

\usepackage{url}

\usepackage[framed,numbered,autolinebreaks,useliterate]{../common/mcode}

\graphicspath{{figures/}}

\title{ScatNet Implementation Document}

\begin{document}
	
\maketitle

\section{Introduction}

\section{The Scattering Transform}

The scattering transform is implemented in ScatNet using the \mcode{scat} function. This function can be used to calculate several types of scattering transforms by varying the linear operators supplied to it.

\subsection{The \mcode{scat} Function}

The \mcode{scat} function takes as input a signal \mcode{x} and a set of linear operators \mcode{Wop} and outputs a scattering transform \mcode{S} and intermediate modulus coefficients \mcode{U}. A call to the \mcode{scat} thus looks like
\begin{lstlisting}
[S, U] = scat(x, Wop);
\end{lstlisting}
Often, the modulus coefficients \mcode{U} are not necessary and so can be left out.

Outputs \mcode{S} and \mcode{U} are cell arrays, each element corresponding to a layer of the scattering transform. The format of these layers is described in the next subsection.

Each element of the \mcode{Wop} is a function handle, with signature
\begin{lstlisting}
[A, V] = Wop{m+1}(X);
\end{lstlisting}
Note that operators are indexed starting at $m = 0$, so an offset of $1$ is necessary for compatibility with MATLAB. Here, \mcode{X}, \mcode{A} and \mcode{V} are all in the network layer format described in the next subsection. The linear operator \mcode{Wop\{m+1\}} transforms the signals in the \mcode{X} into two new layers: an invariant layer \mcode{A} (average) and a covariant layer \mcode{V} (variations). In the case of a wavelet transform, \mcode{A} corresponds to the averaging of the lowpass filter $\phi$ while \mcode{V} consists of the wavelet coefficients obtained by convolving with $\psi_j$.

Initializing \mcode{U{1}} using the input signal, the following loop is then executed in \mcode{scat}
\begin{lstlisting}
for m = 0:numel(Wop)-1
	if (m < numel(Wop)-1)
		[S{m+1}, V] = Wop{m+1}(U{m+1});
		U{m+2} = modulus_layer(V);
	else
		S{m+1} = Wop{m+1}(U{m+1});
	end
end
\end{lstlisting}
For each intermediate layer \mcode{U\{m+1\}}, we thus apply the linear operator \mcode{Wop\{m+1\}}, assigning the invariant output to the $m$th-order scattering layer \mcode{S\{m+1\}}, and computing the modulus of the covariant part to obtain the $(m+1)$th order intermediate coefficients \mcode{U{m+2}}. For the last layer, we do not need the intermediate coefficients, and so only compute the scattering coefficients.

\subsection{Network Layers \mcode{S\{m+1\}} and Linear Operators \mcode{Wop\{m+1\}}}

As mentioned earlier, each element of \mcode{S} and \mcode{U} are in the network layer format. These consist of two fields, \mcode{signal} and \mcode{meta}. The former is a cell array of signals and the latter is a structure containing information related to each signal.

Specifically, each of the fields in \mcode{meta} is an array with the same number of columns as the length of \mcode{signal}. For example, the \mcode{meta.resolution} field has one row, indicating the extent the signal has been subsampled with respect to the original length. In the case of wavelet transforms used as linear operators, an important field is \mcode{meta.j}, which has a variable number of rows, describing the scales of the wavelets used to compute the coefficient. For a first-order coefficient $|x\star\psi_{j_1}|\star\phi(t)$, this will simply be one row containing $j_1$. For a second-order coefficient $||x\star\psi_{j_1}|\star\psi_{j_2}|\star\phi(t)$, the first row will contain $j_1$ while the second will contain $j_2$.

Let us consider the example output \mcode{S} from the \mcode{scat} function using wavelet transforms as linear operators. In this case, \mcode{S\{m+1\}} will contain the $m$th-order scattering coefficients, with \mcode{S\{m+1\}.signal\{p\}} being the $p$th signal among these. Its scales $(j_1,j_2,\ldots,j_m)$ are specified in \mcode{S\{m+1\}.meta.j(:,p)}.

As mentioned earlier, the \mcode{Wop\{m+1\}} function handles take as an input a network layer and outputs two layers, one invariant and one covariant. Any function with these inputs and outputs can be used as an element of \mcode{Wop}. Two basic functions can be used for this purpose: \mcode{wavelet_layer_1d} and \mcode{wavelet_layer_2d}, which define wavelet transforms on network layers. For example, supposing we have defined a filter bank \mcode{filters} (see next section), we can create an accompanying 1D wavelet transform by defining
\begin{lstlisting}
Wop{m+1} = @(U)(wavelet_layer_1d(U, filters));
\end{lstlisting}
This has to be done for each layer of the scattering transform.

\section{Creating Operators}

Linear operators can be constructed manually as indicated in the previous section by defining filters and function handles. However, factory functions presented in this section simplify this process.

\subsection{\mcode{wavelet_factory_1d}}

The \mcode{wavelet_factory_1d} function takes a signal size along with a number of parameters and returns a cell array of linear operators corresponding to wavelet transforms. Its signature is given by
\begin{lstlisting}
[Wop, filters] = wavelet_factory_1d(N, filt_opt, scat_opt);
\end{lstlisting}
where \mcode{N} is the size of the signal, \mcode{filt_opt} are the filter parameters, \mcode{scat_opt} are other parameters for the wavelet transforms. Specifically, \mcode{scat_opt.M} is the maximal order of the scattering transform (i.e. how many layers/linear operators to create). The function outputs the wavelet transforms \mcode{Wop} and the filters used to define them \mcode{filters}. To calculate the scattering, only the former are necessary.

Default filter options are obtained by calling \mcode{default_filter_options}, which takes as input a type of filter and an averaging scale. The type of filter is one of \mcode{'audio'}, \mcode{'dyadic'} or \mcode{'image'}, corresponding to audio signals, other (less oscillatory) 1D signals, and images, respectively. The averaging scale determines the size of the largest wavelet and consequently that of the lowpass filter $\phi$. For more filter options, see next section.

The \mcode{scat_opt} supports the following options:
\begin{itemize}
	\item \mcode{scat_opt.oversampling}: The extent to which the final scattering output is oversampled. Specifically, the sampling rate is \mcode{2^scat_opt.oversampling} times the critical sampling rate. By default equal to \mcode{1}.
\end{itemize}
To specify default values, \mcode{scat_opt} can be left empty.

Using the above information, we can create a second-order scattering transform for an audio signal of length $65536$ with an averaging scale of $4096$
\begin{lstlisting}
filt_opt = default_filter_options('audio', 4096);
scat_opt.M = 2;

Wop = wavelet_factory_1d(65536, filt_opt, scat_opt);
\end{lstlisting}
The scattering transform of a signal \mcode{x} is then obtained by calling \mcode{scat(x, Wop)}.

\subsection{\mcode{wavelet_factory_2d}}
The \mcode{wavelet_factory_2d} function takes a \mcode{size_in} vector of image size and optional parameters wrapped in an \mcode{filt_opt} and \mcode{scat_opt} structure of options parameters and outputs a cell array of linear operators corresponding to successive wavelet transforms. Its signature  is given by
\begin{lstlisting}
[Wop, filters] = wavelet_factory_2d(size_in, filt_opt, scat_opt)
\end{lstlisting}
The \mcode{scat_opt} options are specific to the scattering algorithm. It can contain the following fields :
\begin{itemize}
	\item \mcode{scat_opt.M} the maximum scattering order. By default equal to \mcode{2}.
	\item \mcode{scat_opt.oversampling} the extent to which the final scattering output is oversampled. Specifically, the sampling rate is \mcode{2^scat_opt.oversampling} times the critical sampling rate. By default equal to \mcode{1}.
	\item \mcode{precision_4byte}: if set to 1 (its default value), output of wavelet transforms will be stored in 4 bytes float instead of 8 bytes double to save memory.
\end{itemize}
The \mcode{filt_opt} options are specific to the filter bank used in wavelet transforms. The possible fields for \mcode{filt_opt} are detailed in section \ref{sec_filters_2d}.

\section{Defining Filters}

As described in the previous section, filter parameters are specified in the \mcode{filt_opt} structure passed to \mcode{wavelet_factory_1d} or \mcode{wavelet_factory_2d}. Depending on the type of filter used, this structure can contain different parameters, but the following can always be specified:
\begin{itemize}
	\item \mcode{filt_opt.filter_type}: The wavelet type, such as `morlet\_1d', `morlet\_2d', `spline\_1d', for example (default \mcode{'morlet_1d'} for 1D signals, \mcode{'morlet_2d'} for 2D signals).
	\item \mcode{filt_opt.precision}: The numeric precision of the filters. Either \mcode{'double'} or \mcode{'single'} (default \mcode{'double'}).
\end{itemize}
Since the \mcode{filter_type} field determines the type of filter bank to create, it determines what other options can be specified. The rest of this section covers the different types of filters and their parameters.

For 1D signals, it is often useful to specify different filter parameters for different orders. This is done by using arrays instead of scalar values for parameters in \mcode{filt_opt}. In the case of numeric parameters, this means that they are regular arrays, whereas for string parameters, such as \mcode{filter_type}, they are cell arrays.

For example, setting \mcode{filt_opt.filter_type = \{'gabor\_1d','spline_1d'\}}, means that the first-order filter bank should be a Gabor filter bank whereas the second should be a spline wavelet filter bank. If more filter banks are needed than parameters are available in \mcode{filt_opt}, the last element in each array is repeated as necessary.

\subsection{1D Morlet/Gabor Filters}
The Gabor wavelets consist of Gaussian envelopes modulated by complex exponentials to cover the entire frequency spectrum. Morlet wavelets are derived from these by subtracting the envelope multiplied by a constant such that the integral of the filter equals zero. As they are closely related, the Gabor and Morlet wavelet have identical sets of options.

These are obtained by setting \mcode{filt_opt.filter_type} to \mcode{'morlet_1d'} or \mcode{'gabor_1d'}, respectively. The Morlet filters are the default filters for 1D signals. 

The Morlet/Gabor filter bank has the following options:
\begin{itemize}
	\item \mcode{filt_opt.Q}: The number of wavelets per octave. By default $1$.
	\item \mcode{filt_opt.J}: The number of wavelet scales.
	\item \mcode{filt_opt.B}: The reciprocal octave bandwidth of the wavelets. By default \mcode{filt_opt.Q}.
	\item \mcode{filt_opt.sigma_psi}: The standard deviation of the mother wavelet in space. By default calculated from \mcode{filt_opt.B}.
	\item \mcode{filt_opt.sigma_phi}: The standard deviation of the scaling function in space. By default calculated from \mcode{filt_opt.B}.
\end{itemize}
The maximal wavelet bandwidth (in space) is determined by $2^{J/Q}$ times the bandwidth of the mother wavelet, which is proportional to \mcode{sigma\_psi}. If \mcode{sigma\_psi} is smaller than a certain threshold, a number of constant-bandwidth filters are added, linearly spaced, to cover the low frequencies.

Again, we can specify different filter banks by setting \mcode{filt_opt.Q} and \mcode{filt_opt.J}, etc. to arrays instead of scalars. This is often useful if the nature of the signal is different at different orders, which is usually the case in audio. For this reason, the \mcode{default_filter_options} for \mcode{'audio'} specify \mcode{filt_opt.Q = [8 1]}, whereas for \mcode{'dyadic'}, \mcode{filt_opt.Q} is set to \mcode{1}. A higher frequency resolution is needed in audio for the first-order filter banks due to the highly oscillatory structure of the signals.

To calculate the appropriate \mcode{J} necessary for a given window size \mcode{T} and filter parameters \mcode{filt_opt}, there is the conversion function \mcode{T_to_J}, which is called using:
\begin{lstlisting}
	filt_opt.J = T_to_J(T, filt_opt);
\end{lstlisting}
This will ensure that the maximum wavelet scale, and thus the averaging scale of the lowpass filter, will be approximately \mcode{T}. Note that the previous prototype, \mcode{T_to_J(T,Q,B,phi_bw_multiplier)} is no longer supported in this version.

\subsection{1D Spline Filters}
The spline wavelet filter bank is an unitary filter bank as defined in \cite{mallatbook}. As a result, the scattering transform defined using these filters has perfect energy conservation \cite{stephane}.

In addition to the parameters listed above, the spline filter bank has the following options:
\begin{itemize}
	\item \mcode{filt_opt.J}: The number of wavelet scales.
	\item \mcode{filt_opt.spline_order}: The order of the splines. Only linear (spline order $1$) and cubic (spline order $3$) are supported.
\end{itemize}
The maximal bandwidth is specified here by $2^J$.

\subsection{2D Morlet Filters}
\label{sec_filters_2d}
The Gabor wavelets consist of Gaussian envelopes modulated by complex exponentials to cover the en- tire frequency spectrum. Morlet wavelets are derived from these by subtracting the envelope multiplied by a constant such that the integral of the filter equals zero. 

A 2D Morlet filter bank consists in a gaussian window 
\begin{equation}
\phi_J (u) =  2^{-2j/Q} \phi(2^{-j/Q} (u,v))
\end{equation}
and in dilated and rotated Morlet filters.
\begin{equation}
\psi_{j, \theta}(u) = 2^{-2j/Q} \psi(r_\theta 2^{-j/Q} (u,v)) 
\end{equation}
with 
\begin{eqnarray}
j & \in & [0,J-1] \\
\pi^{-1} L^{-1} \theta & \in & [0,L-1]
\end{eqnarray}
The full filter bank can be obtained by calling 
\mcode{morlet_filter_bank_2d}. 
\begin{lstlisting}
size_in = [128, 128];
filt_opt.L = 6;
filt_opt.Q = 1;
filt_opt.J = 3;
filters = morlet_filter_bank_2d(size_in, filt_opt);
\end{lstlisting}
This example builds a \mcode{128x128} filter bank with the following options :
\begin{itemize}
	\item \mcode{filt_opt.Q} the number of wavelets per octave. By default $1$.
	\item \mcode{filt_opt.J}  the number of wavelet scales. By default $4$.
	\item \mcode{filt_opt.L}  the number of wavelet orientations. By default $8$.
\end{itemize}	



The mother Morlet filter is
\begin{equation}
\label{eq_mother_morlet}
\psi(u,v) = e^{ \frac{u^2 + s^2 v^2}{2 \sigma^2}}(K - e^{i u \xi})
\end{equation}
Its parameters are
\begin{itemize}
\item $\sigma$ the spread of the gaussian envelope 
\item $\xi$ the frequency of the oscillatory exponential
\item $s$ the eccentricity of the elliptical gaussian enveloppe
\end{itemize}
Setting \mcode{Q} and \mcode{L} influences the default parameters of the mother Morlet filter $\sigma$, 
$\xi$ and $s$. For example, increasing $L$ also increases the angular resolution by decreasing $\xi$.
This adaptive behavior can be overridden by manually setting $\sigma$, $\xi$, $s$ in the \mcode{filt_opt} structure.
\begin{itemize}
	\item \mcode{filt_opt.sigma_phi} the spread of $\phi$
	\item \mcode{filt_opt.sigma_psi} the spread $\sigma$ in (\ref{eq_mother_morlet})
	\item \mcode{filt_opt.xi_psi} the frequency $\xi$ in (\ref{eq_mother_morlet})
	\item \mcode{filt_opt.slant_psi} the eccentricity $s$ in (\ref{eq_mother_morlet})
\end{itemize}	


\section{Manipulating, Formatting Scattering Coefficients}

To facilitate the manipulation of the scattering coefficients, several functions are provided that perform different operations on the network layer format described above. In addition, we can convert the coefficients to an easier-to-manage array representation, concatenating scattering coefficients and separating out meta-data.

\subsection{Post-processing}

This section describes the different post-processing function that are available to apply to scattering coefficients.

\subsubsection{\mcode{renorm_scat}}
As described in \cite{joakim}, second-order scattering coefficients can be renormalized by dividing $Sx(t,j_1,j_2)$ by $Sx(t,j_1)$, which decorrelates the second order from the first. A similar procedure is available for higher orders.

In ScatNet, this transformation is available through the \mcode{renorm_scat} function. Its signature is as follows
\begin{lstlisting}
S_renorm = renorm_scat(S, epsilon);
\end{lstlisting}
where \mcode{S} is the scattering transform to be renormalized, and \mcode{epsilon} is a regularization constant that prevents the fraction from diverging when the first order becomes zero.

\subsubsection{\mcode{log_scat}}
For several signals, it is sometimes necessary to compute the logarithm of scattering coefficients. This is achieved in ScatNet using the \mcode{log_scat} function. Its signature is
\begin{lstlisting}
S_log = log_scat(S, epsilon);
\end{lstlisting}
where \mcode{S} is the scattering transform whose logarithm we want to compute, and \mcode{epsilon} is a regularization constant that prevents the logarithm from going to negative infinity when the scattering coefficients approach zero.

\subsubsection{\mcode{average_scat}}

\subsection{Formatting}

In order to use the scattering coefficients for classification and other tasks, it is often useful to convert the representation into a purely numeric format, separating out the metadata. This is the role of the \mcode{format_scat} function, whose signature is
\begin{lstlisting}
[S_table, meta] = format_scat(S, fmt);
\end{lstlisting}
where \mcode{S} is the scattering transform, \mcode{fmt} is the type of output we want, \mcode{S_table} is the formatted output, and \mcode{meta} contain the metadata from \mcode{S} associated with the signals in \mcode{S_table}.

There are three different formats available for \mcode{fmt}. The first is \mcode{'raw'}, which leaves the representation intact, setting \mcode{S_table = S}. The second is \mcode{'order_table'}, which creates a two-dimensional table for each scattering order, and sets \mcode{S_table} to the cell array of these tables, with \mcode{meta} being a cell array of the associated \mcode{S\{m+1\}.meta}. Finally, \mcode{'table'} (the default), concatenates the tables of all orders and does the same for the meta fields. In the case where \mcode{meta} fields have different number of rows for different orders, the smaller fields are extended with \mcode{-1}. Note that this last format is only possible if scattering coefficients of different orders are of the same resolution, which is most often the case.

\section{Display}

\subsection{1D}

\subsubsection{\mcode{scattergram}}

The \mcode{scattergram} function displays the scattering coefficients as a function of time and the last filter index with the remaining filter indices fixed. For first-order coefficients, this means that it is shown as a function of time and $j_1$. For second-order coefficients, it is shown as a function of time and $j_2$ for a fixed $j_1$, and so on.

For one display, a pair consisting of a scattering layer along with a scale prefix is needed. We can specify multiple displays by specifying multiple of these pairs, which will then be displayed one on top of the other.

Its signature is the following
\begin{lstlisting}
img = scattergram(S{m1+1}, jprefix_1, S{m2+1}, jprefix_2, ...);
\end{lstlisting}
where \mcode{S} is the scattering transform, \mcode{m1} is the order of the first display, \mcode{jprefix_1} is the first scale prefix, and so on. Note that is \mcode{m1 = 1} the layer is of first order so no scale prefix is necessary and we set \mcode{jprefix_1} to \mcode{[]}.

Instead of a scattering output \mcode{S}, we can also specify intermediate modulus coefficients \mcode{U}.

\subsection{2D}

The \mcode{image_scat} opens one figure per layer and display all the path of a layer in the corresponding figure. Its signature is 
\begin{lstlisting}
Sx = scat(x, Wop);
% display scattering coefficients
image_scat(Sx)
\end{lstlisting}

To display all the coefficients of a particular layer, one can use 
\begin{lstlisting}
m = 2;
image_scat_layer(Sx{m+1})
\end{lstlisting}
This stacks all paths of the layer next to each other, renormalize them and overlay their meta information. Both these feature can be turned off using
\begin{lstlisting}
m = 2;
image_scat_layer(S{m+1}, 0, 0);
\end{lstlisting}
Paths can also be arranged in a specific order along rows and column.
For example, the following arranges scattering coefficient of second order
by lexicographic order on $j$ along rows and lexicographic order on $\theta$ along columns.
\begin{lstlisting}
var_y{1}.name = 'j';
var_y{1}.index = 1;
var_y{2}.name = 'j';
var_y{2}.index = 2;
var_x{1}.name = 'theta';
var_x{1}.index = 1;
var_x{2}.name = 'theta';
var_x{2}.index = 2;
m = 2;
image_scat_layer_order(S{3},var_x, var_y,1);
\end{lstlisting}
The spatial coefficients of all filter of a filter bank can be displayed using
\begin{lstlisting}
display_filter_bank_2d(filters);
\end{lstlisting}

\section{Classification}

ScatNet contains a classification pipeline for affine space and support vector classifiers. These let the user specify a feature transformation for computing features in batch form, then set up a training/testing mechanism for evaluating results.

\subsection{Batch Computation}

To compute scattering coefficients for a database of signals, we first define a source. A source is a set of files, each file containing a number of objects to be classified. Each object has a class and a location within the file.

The source can be created using \mcode{create_src(directory, extract_objects_fun)} (or one of its wrappers, such as \mcode{gtzan_src}, \mcode{phone_src}, \mcode{uiuc_src}, etc). Given a directory, this function recursively traverses it, looking for `.jpg', `.wav', or `.au' files. For each such file, it calls \mcode{extract_objects_fun} to determine its constituent objects and their classes. To add a new database, it suffices to write the corresponding \mcode{extract_objects_fun} function.

The \mcode{extract_objects_fun} function has the following signature
\begin{lstlisting}
[objects, classes] = extract_objects_fun(file);
\end{lstlisting}
Given a file, it returns a structure array \mcode{objects} of the objects it contains and a cell array of their class names \mcode{classes}. The structure of the \mcode{objects} variable is described below.

Most often, a file will only contain one object, so \mcode{objects} is a  structure of size one, but this can vary from database to database (for example in speech recognition a file corresponds to a recording of a phrase, which can contain different phones to be classified).

The objects structure has the fields \mcode{objects.u1} and \mcode{objects.u2} which correspond to the lower-left and upper-right corners (start- and endpoints) of the object in a 2D (or 1D) signal. These bounds are inclusive. For the case where a file only contains one object, the bounds will simply be the bounds of the signal. If desired, additional fields can be specified that will be passed on and saved in the source structure.

Given a directory and this function, \mcode{create_src} returns a source structure \mcode{src}, which has the following fields
\begin{itemize}
	\item \mcode{src.classes}: A cell array of the class names.
	\item \mcode{src.files}: A cell array of the file names.
	\item \mcode{src.objects}: A struct array of the objects returned by applying \mcode{objects_fun} to each filename, but with two supplementary fields: \mcode{src.objects.ind}, corresponding to the index of its parent filename in \mcode{src.files} and \mcode{src.objects.class}, corresponding to the index of its class in \mcode{src.classes}.
\end{itemize}

The scattering coefficients of the objects in \mcode{src} can now be calculated using the function \mcode{prepare_database}. This function takes for input the \mcode{src} structure, a function handle \mcode{feature_fun}, which calculates the feature representation, and an options structure. If we want to calculate multiple feature representations and concatenate the results, their feature functions can be assembled into a cell array and given instead of \mcode{feature_fun}.

A ``feature function'' takes as input one or more signals and returns the their feature vectors. Its signature is thus
\begin{lstlisting}
features = feature_fun(signal);
\end{lstlisting}

When \mcode{signal} is a 1D signal, \mcode{features} should be a 2D matrix (potentially just a column vector) where the first dimension is the feature index and the second dimension is a time index. The \mcode{signal} argument can also be a collection of 1D signals, arranged as a columns of a 2D matrix. In this case, the output \mcode{features} is a 3D array, with the first two dimensions being the same, but the third dimension corresponding to the signal index in \mcode{signal}.

Similarly, for \mcode{signal} being a 2D signal, \mcode{features} is a 2D matrix with first dimension corresponding to feature dimension and the second dimension corresponding to a space index. Again, multiple 2D signals can be given to \mcode{feature_fun} by specifying \mcode{signal} to be a 3D array, with signals arranged along the third dimension. The output \mcode{features} will then also be a 3D array as in the 1D case.

Note that a feature function is not required to output only one feature vector for each signal. That is, it can leave a time/space index in the output feature representation. If more than one feature vector is associated to a single signal object, the classifier will classify each feature vector separately and aggregate the results, either through averaging the approximation error (for the affine space classifier) or through voting (for the SVM classifier). If this is not desired, the user has to make sure that the feature function only returns feature vectors with one time index per signal.

The \mcode{scat} function, combined with the \mcode{format_scat} function, fulfills the above criteria. As such, we can use it to define a feature function for \mcode{prepare_database}. For batch calculation of second-order audio scattering vectors for the GTZAN dataset, we have the following code.
\begin{lstlisting}
N = 5*2^17;
src = gtzan_src;

filt_opt = default_filter_options('audio', 8192);
scat_opt.M = 2;

Wop = wavelet_factory_1d(N, filt_opt, scat_opt);

feature_fun = @(x)(format_scat( ...
	log_scat(renorm_scat(scat(x, Wop)))));
	
database_opt = struct();
	
database = prepare_database(src, feature_fun, database_opt);
\end{lstlisting}
Observe the signal length \mcode{N}, which is equal to the length of the signals contained in \mcode{gtzan_src}. 

The \mcode{database_opt} contains options given to \mcode{prepare_database}. These include:
\begin{itemize}
	\item \mcode{database_opt.feature_sampling}: The factor by which the features should be downsampled. Useful for reducing computational complexity of the classifier training and testing (default \mcode{1} - no downsampling).
	\item \mcode{database_opt.file_normalize}: The norm to use when normalizing each file. Can be either \mcode{1}, \mcode{2}, \mcode{Inf} or \mcode{[]}, corresponding to $\mathbf{l}^1$, $\mathbf{l}^2$, $\mathbf{l}^\infty$ norms and no normalization, respectively (default \mcode{[]}).
	\item \mcode{database_opt.parallel}: If \mcode{1}, \mcode{prepare_database} will attempt to parallelize the code by using the \mcode{parfor} construct from the MATLAB Distributed Computing Toolbox. Note that if this is not available, performance may be worse since MATLAB will only use one core (default \mcode{1}).
\end{itemize}

The resulting \mcode{database} structure now contains three fields:
\begin{itemize}
	\item \mcode{database.src}: The original \mcode{src} structure from which the features were computed.
	\item \mcode{database.features}: The feature vectors, arranged in a 2D matrix, each feature vector forming a column.
	\item \mcode{database.indices}: The indices corresponding to each object in \mcode{database.src}. Specifically, \mcode{database.features(:,database.indices\{k\})} contains the features vector(s) calculated from \mcode{database.src.objects(k)}. If there is one feature vector per object, each element of \mcode{database.indices} is a scalar.
\end{itemize}

\subsection{Classifier Framework}
Once the database of feature vectors is constructed, models can be trained and tested. To create a train/test partition, the function \mcode{create_partition} is available. Given a source \mcode{src} and a ratio, it partitions the objects so that each class is divided evenly into the training and testing set according to the ratio. For example, the following code defines a train/test partition with $80\%$ of the objects in the training set:
\begin{lstlisting}
[train_set, test_set] = create_partition(src, 0.8);
\end{lstlisting}
Here, \mcode{train_set} will contain the indices in \mcode{src.objects} that correspond to the training instances, while \mcode{test_set} will contain those corresponding to testing instances.

Alternatively, a partition can be defined manually by traversing the \mcode{src.objects} array and recording the desired indices.

Given a partition, a model can be trained using the appropriate training function. We will denote the training function by \mcode{train}, but in reality it will be either \mcode{affine_train} or \mcode{svm_train}. The training is then done by:
\begin{lstlisting}
model = train(database, train_set, train_opt);
\end{lstlisting}
The structure \mcode{train_opt} contains various parameters for training the model, which will depend on the type of classifier used.

To test the model, the functions \mcode{affine_test} and \mcode{svm_test} are used. Here, we denote the testing function by \mcode{test}. The labels obtained for the testing instances specified by \mcode{test_set} are then obtained by:
\begin{lstlisting}
labels = test(database, model, test_set);
\end{lstlisting}
To calculate the classification error, the \mcode{classif_err} is used:
\begin{lstlisting}
err = classif_err(labels, test_set, src);
\end{lstlisting}
Note that the original \mcode{src} structure is necessary here to verify the class membership of the testing instances.

To calculate the errors over a range of training parameters in \mcode{train_opt}, the functions \mcode{affine_param_search} and \mcode{svm_param_search} are available. Denoting them both by \mcode{param_search}, they have the following signature
\begin{lstlisting}
[err, param1, param2] = param_search( ...
	database, train_set, valid_set, train_opt);
\end{lstlisting}
Where \mcode{database} and \mcode{train_set} are the feature database and training set, respectively, \mcode{valid_set} is a validation set to calculate the errors on and \mcode{train_opt} contain the training parameters for the model. Multiple training parameters are specified by setting the field to an array instead of a scalar in \mcode{train_opt}. The classification error for different parameter combinations is then given in \mcode{err}, with the actual parameter values stored in \mcode{param1}, \mcode{param2}, etc.

The validation set can be taken to be \mcode{test_set}, but this would lead to overfitting of the parameters. For some tasks, a separate validation test is given for this purpose. Another alternative is to perform cross-validation on the training set \mcode{train_set}. This is obtained by setting \mcode{test_set} to \mcode{[]}. By default, \mcode{param_search} will then split \mcode{train_set} into five parts, train on four and test on the remaining one, then shuffle and repeat. The number of folds can be determined by the \mcode{train_opt.cv_folds} option. In this case, \mcode{err} is a 2D matrix, with the parameter set index along the first dimension and the fold index along the second. To obtain the best parameter set, an average can then be performed along the fold index.

\subsection{Affine Space Classifier}

The affine classifier is defined by the functions \mcode{affine_train} and \mcode{affine_test}. The former takes as an option the number of dimensions, \mcode{train_opt.dim} used for the affine space model of each class. 

The following code calculates the error for an affine space classifier dimension $40$:
\begin{lstlisting}
train_opt.dim = 40;
model = affine_train(database, train_set, train_opt);
labels = affine_test(database, model, test_set);
err = classif_err(labels, test_set, src);
\end{lstlisting}

For an affine space classifier, the model structure contains the dimension for which it is defined \mcode{model.dim}, the centers of the classes \mcode{model.mu} (a cell array) and the direction vectors defining the affine space \mcode{model.v} (a cell array).

In addition to the labels, \mcode{affine_test} can also output the approximation errors for each feature vector and object. This is done by the additional outputs \mcode{obj_err} and \mcode{feature_err}, as in the following call:
\begin{lstlisting}
[labels, obj_err, feature_err] = affine_test(database, model, test_set);
\end{lstlisting}
Here, \mcode{obj_err} is a 2D matrix with the first dimension corresponding to the class index of the affine space the object was approximated using and the second dimension corresponding to the object index. Similarly, \mcode{feature} is a 2D matrix with first dimension being the class index and the second dimension corresponding to the feature vector index, arranged according to the objects they belong to. That is, the feature vectors of \mcode{test_set(1)} come first, then those of \mcode{test_set(2)}, etc. Note that \mcode{obj_err} can be calculated from \mcode{feature_err} by averaging over the all the feature vectors for one object.

To find the optimal dimension of the affine space, \mcode{affine_param_search} is used, with a range of dimensions specified for \mcode{train_opt.dim}. Specifically, we call
\begin{lstlisting}
[err, dim] = affine_param_search(database, train_set, valid_set, train_opt);
\end{lstlisting}
where \mcode{database}, \mcode{train_set}, \mcode{valid_set}, \mcode{train_opt} are as described in the previous subsection. The output \mcode{dim} is equal to \mcode{train_opt.dim}, and \mcode{err} contains the errors for this range of dimensions.

\subsection{Support Vector Classifier}

\textbf{NOTE: Requires the LIBSVM library, see \url{http://www.csie.ntu.edu.tw/~cjlin/libsvm/}}

The support vector machine classifier is defined by the functions \mcode{svm_train} and \mcode{svm_test}. The training options consist of:
\begin{itemize}
	\item \mcode{train_opt.kernel_type}: The kernel type used in the SVM. Can be \mcode{'linear'} for a linear kernel $u^Tv$ or \mcode{'gaussian'} for a Gaussian kernel $e^{-\gamma\|u-v\|^2}$.
	\item \mcode{train_opt.C}: The slack factor $C$ used for training the SVM.
	\item \mcode{train_opt.gamma}: The regularity constant $\gamma$ used in the case of a Gaussian SVM kernel.
\end{itemize}

The following code calculates the error for an SVM classifier with a linear kernel and $C = 8$:
\begin{lstlisting}
train_opt.kernel_type = 'linear';
train_opt.C = 8;
model = svm_train(database, train_set, train_opt);
labels = svm_test(database, model, test_set);
err = classif_err(labels, test_set, src);
\end{lstlisting}

If the feature vectors are very large, which can be the case for scattering coefficients, it is often useful to precalculate the kernel. This significantly speeds up training and testing, but at a cost of memory consumption. To precalculate the kernel, the function \mcode{svm_calc_kernel} is used on \mcode{database}, as in
\begin{lstlisting}
database = svm_calc_kernel(database, kernel_type);
\end{lstlisting}
where \mcode{kernel_type} is either \mcode{'linear'} or \mcode{'gaussian'}. Afterwards, when \mcode{svm_train} is called, it can take advantage of this kernel if the same kernel type is specified in \mcode{train_opt.kernel_type}.

To determine the optimal parameters, a parameter search function \mcode{svm_param_search} is provided, with the same syntax as described above. Its signature is
\begin{lstlisting}
[err, C, gamma] = svm_param_search(database, train_set, valid_set, train_opt);
\end{lstlisting}
where \mcode{database}, \mcode{train_set}, \mcode{valid_set}, \mcode{train_opt} are as described previously. We set the values of \mcode{C} and \mcode{gamma} that we wish to test in \mcode{train_opt}. All combinations of these parameters are then evaluated, with errors recorded in \mcode{err} and the particular values for each set stores in \mcode{C} and \mcode{gamma}.

Since parameters can vary over a large domain, and a fine-grained parameter search can be quite costly, there is also an adaptive parameter search function, \mcode{svm_adaptive_param_search}. This function calls \mcode{svm_param_search}, recenters the \mcode{C}-\mcode{gamma} parameter grid on the optimal parameter combination while increasing the grid resolution,  then reapplies \mcode{svm_param_search}, and so on. This is done \mcode{train_opt.search_depth} times, which by default equals $2$.

If a linear kernel is used, we can extract the discriminant vector $w$ and bias $\rho$ from the model using the function \mcode{svm_extract_w}. The function takes as input the database \mcode{database} and the SVM model \mcode{model}. It outputs the $w$s corresponding to each pair of classes in the model, arranged in the order $1$vs$2$,$1$vs$3$,\ldots$1$vs$N$,$2$vs$3$,\ldots,$2$vs$N$,\ldots,$(N-1)$vs$N$, where $N$ is the number of classes. The function is called as in:
\begin{lstlisting}
[w,rho] = svm_extract_w(database, model);
\end{lstlisting}

\end{document}
